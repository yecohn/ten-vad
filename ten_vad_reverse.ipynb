{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "347551bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5989982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = onnx.load(\"/home/yehoshua/projects/vad/ten-vad/src/onnx_model/ten-vad.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145cdc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IR version : 4\n",
      "Opsets      : [('ai.onnx', 9), ('ai.onnx.ml', 2)]\n",
      "input_1               FLOAT   ['?', 3, 41]\n",
      "input_2               FLOAT   ['?', 64]\n",
      "input_3               FLOAT   ['?', 64]\n",
      "input_6               FLOAT   ['?', 64]\n",
      "input_7               FLOAT   ['?', 64]\n",
      "output_1              FLOAT   ['?', '?', 1]\n",
      "output_2              FLOAT   [1, 64]\n",
      "output_3              FLOAT   [1, 64]\n",
      "output_6              FLOAT   [1, 64]\n",
      "output_7              FLOAT   [1, 64]\n",
      "  0 Unsqueeze        Unsqueeze__97\n",
      "  1 Unsqueeze        Unsqueeze__95\n",
      "  2 Unsqueeze        Unsqueeze__68\n",
      "  3 Unsqueeze        Unsqueeze__66\n",
      "  4 Unsqueeze        StatefulPartitionedCall/vad_model/ExpandDims\n",
      "  5 Reshape          StatefulPartitionedCall/vad_model/separable_conv2d/separable_conv2d/depthwise__111\n",
      "  6 Conv             StatefulPartitionedCall/vad_model/separable_conv2d/separable_conv2d/depthwise\n",
      "     ├─ attr group: 1\n",
      "  7 Conv             StatefulPartitionedCall/vad_model/separable_conv2d/BiasAdd\n",
      "     ├─ attr group: 1\n",
      "  8 Relu             StatefulPartitionedCall/vad_model/separable_conv2d/Relu\n",
      "  9 MaxPool          StatefulPartitionedCall/vad_model/max_pooling2d/MaxPool\n",
      " 10 Conv             StatefulPartitionedCall/vad_model/separable_conv1d/separable_conv2d/depthwise\n",
      "     ├─ attr group: 16\n",
      " 11 Conv             StatefulPartitionedCall/vad_model/separable_conv1d/BiasAdd\n",
      "     ├─ attr group: 1\n",
      " 12 Squeeze          StatefulPartitionedCall/vad_model/separable_conv1d/Squeeze\n",
      " 13 Relu             StatefulPartitionedCall/vad_model/separable_conv1d/Relu\n",
      " 14 Unsqueeze        StatefulPartitionedCall/vad_model/separable_conv1d_1/ExpandDims\n",
      " 15 Conv             StatefulPartitionedCall/vad_model/separable_conv1d_1/separable_conv2d/depthwise\n",
      "     ├─ attr group: 16\n",
      " 16 Conv             StatefulPartitionedCall/vad_model/separable_conv1d_1/BiasAdd\n",
      "     ├─ attr group: 1\n",
      " 17 Squeeze          StatefulPartitionedCall/vad_model/separable_conv1d_1/Squeeze\n",
      " 18 Relu             StatefulPartitionedCall/vad_model/separable_conv1d_1/Relu\n",
      " 19 Transpose        StatefulPartitionedCall/vad_model/separable_conv1d_1/BiasAdd__147\n",
      " 20 Reshape          StatefulPartitionedCall/vad_model/lstm/PartitionedCall/transpose\n",
      " 21 LSTM             LSTM__73\n",
      "     ├─ attr hidden_size: 64\n",
      " 22 Squeeze          Squeeze__78\n",
      " 23 Squeeze          Squeeze__77\n",
      " 24 Squeeze          Squeeze__75\n",
      " 25 Reshape          StatefulPartitionedCall/vad_model/lstm/PartitionedCall/transpose_1\n",
      " 26 Transpose        StatefulPartitionedCall/vad_model/lstm_2/PartitionedCall/transpose\n",
      " 27 LSTM             LSTM__102\n",
      "     ├─ attr hidden_size: 64\n",
      " 28 Squeeze          Squeeze__109\n",
      " 29 Squeeze          Squeeze__107\n",
      " 30 Squeeze          Squeeze__104\n",
      " 31 Transpose        StatefulPartitionedCall/vad_model/lstm_2/PartitionedCall/transpose_1\n",
      " 32 Concat           StatefulPartitionedCall/vad_model/concat_1\n",
      "     ├─ attr axis: 2\n",
      " 33 Shape            StatefulPartitionedCall/vad_model/dense_3/Tensordot/Shape\n",
      " 34 Cast             StatefulPartitionedCall/vad_model/dense_3/Tensordot/Shape__162\n",
      "     ├─ attr to: 6\n",
      " 35 Gather           StatefulPartitionedCall/vad_model/dense_3/Tensordot/GatherV2\n",
      "     ├─ attr axis: 0\n",
      " 36 Concat           StatefulPartitionedCall/vad_model/dense_3/Tensordot/concat_1\n",
      "     ├─ attr axis: 0\n",
      " 37 Cast             StatefulPartitionedCall/vad_model/dense_3/Tensordot__167\n",
      "     ├─ attr to: 7\n",
      " 38 Reshape          StatefulPartitionedCall/vad_model/dense_3/Tensordot/Reshape\n",
      " 39 MatMul           StatefulPartitionedCall/vad_model/dense_3/Tensordot/MatMul\n",
      " 40 Reshape          StatefulPartitionedCall/vad_model/dense_3/Tensordot\n",
      " 41 Add              StatefulPartitionedCall/vad_model/dense_3/BiasAdd\n",
      " 42 Relu             StatefulPartitionedCall/vad_model/dense_3/Relu\n",
      " 43 Shape            StatefulPartitionedCall/vad_model/dense_5/Tensordot/Shape\n",
      " 44 Cast             StatefulPartitionedCall/vad_model/dense_5/Tensordot/Shape__168\n",
      "     ├─ attr to: 6\n",
      " 45 Gather           StatefulPartitionedCall/vad_model/dense_5/Tensordot/GatherV2\n",
      "     ├─ attr axis: 0\n",
      " 46 Concat           StatefulPartitionedCall/vad_model/dense_5/Tensordot/concat_1\n",
      "     ├─ attr axis: 0\n",
      " 47 Cast             StatefulPartitionedCall/vad_model/dense_5/Tensordot__173\n",
      "     ├─ attr to: 7\n",
      " 48 Reshape          StatefulPartitionedCall/vad_model/dense_5/Tensordot/Reshape\n",
      " 49 MatMul           StatefulPartitionedCall/vad_model/dense_5/Tensordot/MatMul\n",
      " 50 Reshape          StatefulPartitionedCall/vad_model/dense_5/Tensordot\n",
      " 51 Add              StatefulPartitionedCall/vad_model/dense_5/BiasAdd\n",
      " 52 Sigmoid          StatefulPartitionedCall/vad_model/Sigmoid\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx import numpy_helper, shape_inference, helper\n",
    "\n",
    "\n",
    "m = shape_inference.infer_shapes(m)          # fill in missing tensor shapes\n",
    "\n",
    "print(\"IR version :\", m.ir_version)\n",
    "print(\"Opsets      :\", [(o.domain or 'ai.onnx', o.version) for o in m.opset_import])\n",
    "\n",
    "# Inputs / outputs ----------------------------------------------------------\n",
    "for value in list(m.graph.input) + list(m.graph.output):\n",
    "    t = value.type.tensor_type\n",
    "    shape = [d.dim_value or '?' for d in t.shape.dim]\n",
    "    print(f\"{value.name:20}  {onnx.TensorProto.DataType.Name(t.elem_type):6}  {shape}\")\n",
    "\n",
    "# Nodes ---------------------------------------------------------------------\n",
    "for i,node in enumerate(m.graph.node):\n",
    "    print(f\"{i:3d} {node.op_type:15}  {node.name or ''}\")\n",
    "    for a in node.attribute:\n",
    "        # GRU / LSTM have many attributes - shorten output if needed\n",
    "        if a.type == onnx.AttributeProto.INT or a.type == onnx.AttributeProto.FLOAT:\n",
    "            print(f\"     ├─ attr {a.name}: {helper.get_attribute_value(a)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dcdfc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_shape__175                                           (4,)\n",
      "const_fold_opt__178                                      (1, 1, 3, 3)\n",
      "StatefulPartitionedCall/vad_model/separable_conv2d/separable_conv2d/ReadVariableOp_1:0  (16, 1, 1, 1)\n",
      "StatefulPartitionedCall/vad_model/separable_conv2d/BiasAdd/ReadVariableOp:0  (16,)\n",
      "const_fold_opt__179                                      (16, 1, 1, 3)\n",
      "StatefulPartitionedCall/vad_model/separable_conv1d/ExpandDims_2:0  (16, 16, 1, 1)\n",
      "StatefulPartitionedCall/vad_model/separable_conv1d/BiasAdd/ReadVariableOp:0  (16,)\n",
      "const_fold_opt__180                                      (16, 1, 1, 3)\n",
      "StatefulPartitionedCall/vad_model/separable_conv1d_1/ExpandDims_2:0  (16, 16, 1, 1)\n",
      "StatefulPartitionedCall/vad_model/separable_conv1d_1/BiasAdd/ReadVariableOp:0  (16,)\n",
      "new_shape__177                                           (3,)\n",
      "W0__70                                                   (1, 256, 80)\n",
      "R0__71                                                   (1, 256, 64)\n",
      "B0__72                                                   (1, 512)\n",
      "new_shape__176                                           (3,)\n",
      "W0__99                                                   (1, 256, 64)\n",
      "R0__100                                                  (1, 256, 64)\n",
      "B0__101                                                  (1, 512)\n",
      "StatefulPartitionedCall/vad_model/dense_3/Tensordot/free:0  (2,)\n",
      "StatefulPartitionedCall/vad_model/dense/Tensordot/Const_2:0  (1,)\n",
      "StatefulPartitionedCall/vad_model/dense/Tensordot/Reshape_shape__186  (2,)\n",
      "StatefulPartitionedCall/vad_model/dense_3/Tensordot/ReadVariableOp:0  (128, 32)\n",
      "StatefulPartitionedCall/vad_model/dense_3/BiasAdd/ReadVariableOp:0  (32,)\n",
      "StatefulPartitionedCall/vad_model/dense_5/Tensordot/Const_2:0  (1,)\n",
      "StatefulPartitionedCall/vad_model/dense_5/Tensordot/Reshape_shape__183  (2,)\n",
      "StatefulPartitionedCall/vad_model/dense_5/Tensordot/ReadVariableOp:0  (32, 1)\n",
      "StatefulPartitionedCall/vad_model/dense_5/BiasAdd/ReadVariableOp:0  (1,)\n"
     ]
    }
   ],
   "source": [
    "from onnx import numpy_helper\n",
    "param = {t.name: numpy_helper.to_array(t) for t in m.graph.initializer}\n",
    "\n",
    "for k,v in param.items():\n",
    "    print(f\"{k:55}  {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d5b2a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TenVAD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # ─── Conv front-end ──────────────────────────────────────────\n",
    "        self.conv_dw = nn.Conv2d(1, 1, kernel_size=(3,3),\n",
    "                         padding=(0,1),  # <── only width is padded\n",
    "                         bias=False)\n",
    "        self.conv_pw = nn.Conv2d(1, 16, kernel_size=1, bias=True)\n",
    "        self.relu    = nn.ReLU()\n",
    "        self.pool    = nn.MaxPool2d((1,2))\n",
    "\n",
    "        self.sep1_dw = nn.Conv2d(16, 16, kernel_size=(1,3),\n",
    "                                padding=(0,0), groups=16, bias=False)\n",
    "        self.sep1_pw = nn.Conv2d(16, 16, kernel_size=1,  bias=True)\n",
    "\n",
    "        self.sep2_dw = nn.Conv2d(16, 16, kernel_size=(1,3),\n",
    "                                padding=(0,0), groups=16, bias=False)\n",
    "        self.sep2_pw = nn.Conv2d(16, 16, kernel_size=1,  bias=True)\n",
    "\n",
    "        # ─── RNN core ────────────────────────────────────────────────\n",
    "        self.lstm1 = nn.LSTM(64, 64, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(64, 64, batch_first=True)\n",
    "\n",
    "        # ─── Densities ───────────────────────────────────────────────\n",
    "        self.fc1 = nn.Linear(128, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, h1=None, c1=None, h2=None, c2=None):\n",
    "        # x: (B, 3, 41)  → (B, 1, 3, 41)\n",
    "        B = x.size(0)\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        x = self.conv_dw(x)          # (B, 1, 1, 41)\n",
    "        x = self.conv_pw(x)          # (B,16, 1, 41)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)             # (B,16, 1, 20)\n",
    "\n",
    "        # ─ separable_conv1d (really 2-D) ─\n",
    "        x = self.sep1_dw(x)          # (B,16,1,18)\n",
    "        x = self.sep1_pw(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.squeeze(2)             # (B,16,18)\n",
    "\n",
    "        # put the singleton height back for the second block\n",
    "        x = x.unsqueeze(2)           # (B,16,1,18)\n",
    "        x = self.sep2_dw(x)          # (B,16,1,16)\n",
    "        x = self.sep2_pw(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.squeeze(2)             # (B,16,16)\n",
    "\n",
    "        # transpose for the LSTM that follows later\n",
    "        x = x.permute(0, 2, 1)       # (B, 16, 16)  -> think of 16 frames × 16 feat\n",
    "\n",
    "        # LSTM stack\n",
    "        h1 = torch.zeros(1,B,64, device=x.device) if h1 is None else h1\n",
    "        c1 = torch.zeros(1,B,64, device=x.device) if c1 is None else c1\n",
    "        x, (h1, c1) = self.lstm1(x, (h1, c1))\n",
    "\n",
    "        h2 = torch.zeros(1,B,64, device=x.device) if h2 is None else h2\n",
    "        c2 = torch.zeros(1,B,64, device=x.device) if c2 is None else c2\n",
    "        x, (h2, c2) = self.lstm2(x, (h2, c2))\n",
    "\n",
    "        # concat last outputs of both directions (here unidirectional so just x)\n",
    "        x = torch.cat([x], dim=2)   # (B, T, 64) → keep for dense\n",
    "\n",
    "        # dense layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.sig(x), (h1,c1,h2,c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "854b445a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 64, got 16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dummy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m41\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[43mTenVAD\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(out\u001b[38;5;241m.\u001b[39mshape)   \u001b[38;5;66;03m# should be (5, 20, 1)  → matches ONNX output_1\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[10], line 61\u001b[0m, in \u001b[0;36mTenVAD.forward\u001b[0;34m(self, x, h1, c1, h2, c2)\u001b[0m\n\u001b[1;32m     59\u001b[0m h1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m,B,\u001b[38;5;241m64\u001b[39m, device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mif\u001b[39;00m h1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m h1\n\u001b[1;32m     60\u001b[0m c1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m,B,\u001b[38;5;241m64\u001b[39m, device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mif\u001b[39;00m c1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m c1\n\u001b[0;32m---> 61\u001b[0m x, (h1, c1) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m h2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m,B,\u001b[38;5;241m64\u001b[39m, device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mif\u001b[39;00m h2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m h2\n\u001b[1;32m     64\u001b[0m c2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m,B,\u001b[38;5;241m64\u001b[39m, device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mif\u001b[39;00m c2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m c2\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1120\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1117\u001b[0m             hx \u001b[38;5;241m=\u001b[39m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[0;32m-> 1120\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1002\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[1;32m    999\u001b[0m     hidden: \u001b[38;5;28mtuple\u001b[39m[Tensor, Tensor],  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m     batch_sizes: Optional[Tensor],\n\u001b[1;32m   1001\u001b[0m ):\n\u001b[0;32m-> 1002\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(\n\u001b[1;32m   1004\u001b[0m         hidden[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1005\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1007\u001b[0m     )\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(\n\u001b[1;32m   1009\u001b[0m         hidden[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1012\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/site-packages/torch/nn/modules/rnn.py:314\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    312\u001b[0m     )\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    316\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 64, got 16"
     ]
    }
   ],
   "source": [
    "dummy = torch.randn(5,3,41)\n",
    "out, _ = TenVAD()(dummy)\n",
    "print(out.shape)   # should be (5, 20, 1)  → matches ONNX output_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38f6edf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
