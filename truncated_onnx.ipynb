{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx \n",
    "from onnx import shape_inference\n",
    "import onnxruntime  as rt\n",
    "import pickle\n",
    "import torch\n",
    "from ten_vad_reconstructed import TenVAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TenVAD(\n",
       "  (conv_dw): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (conv_pw): Conv2d(1, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (relu): ReLU()\n",
       "  (pool): MaxPool2d(kernel_size=(1, 3), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (sep1_dw): Conv2d(16, 16, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), groups=16, bias=False)\n",
       "  (sep1_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (sep2_dw): Conv2d(16, 16, kernel_size=(1, 3), stride=(2, 2), groups=16, bias=False)\n",
       "  (sep2_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (lstm1): LSTM(80, 64, batch_first=True)\n",
       "  (lstm2): LSTM(64, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  onnx.load(\"ten_vad_exported.onnx\")\n",
    "model = shape_inference.infer_shapes(model)\n",
    "state_dict = torch.load(\"ten_vad_onnx_weights.pth\")\n",
    "torch_model = TenVAD().to('cuda')\n",
    "torch_model.load_state_dict(state_dict)\n",
    "torch_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_outputs = []\n",
    "for val_info in model.graph.value_info:\n",
    "    new_outputs.append(val_info)\n",
    "    \n",
    "for o in new_outputs:\n",
    "    model.graph.output.append(o)\n",
    "\n",
    "onnx.save(model, \"debug_torch_model.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_model = onnx.load(\"src/onnx_model/ten-vad.onnx\")\n",
    "orig_model =  onnx.load(\"src/onnx_model/ten-vad.onnx\")\n",
    "orig_model = shape_inference.infer_shapes(orig_model)\n",
    "new_outputs = []\n",
    "for val_info in orig_model.graph.value_info:\n",
    "    new_outputs.append(val_info)\n",
    "    \n",
    "for o in new_outputs:\n",
    "    orig_model.graph.output.append(o)\n",
    "\n",
    "onnx.save(orig_model, \"debug_onnx_model.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output\n",
      "159\n",
      "160\n",
      "220\n",
      "221\n",
      "/Unsqueeze_output_0\n",
      "/Constant_output_0\n",
      "/Reshape_output_0\n",
      "/conv_dw/Conv_output_0\n",
      "/conv_pw/Conv_output_0\n",
      "/relu/Relu_output_0\n",
      "/pool/MaxPool_output_0\n",
      "/sep1_dw/Conv_output_0\n",
      "/sep1_pw/Conv_output_0\n",
      "/Constant_1_output_0\n",
      "/Shape_output_0\n",
      "/Gather_output_0\n",
      "/Constant_2_output_0\n",
      "/Equal_output_0\n",
      "/If_output_0\n",
      "/relu_1/Relu_output_0\n",
      "/Unsqueeze_1_output_0\n",
      "/Constant_3_output_0\n",
      "/Constant_4_output_0\n",
      "/ConstantOfShape_output_0\n",
      "/Concat_output_0\n",
      "/Constant_5_output_0\n",
      "/Reshape_1_output_0\n",
      "/Constant_6_output_0\n",
      "/Constant_7_output_0\n",
      "/Constant_8_output_0\n",
      "/Constant_9_output_0\n",
      "/Slice_output_0\n",
      "/Transpose_output_0\n",
      "/Constant_10_output_0\n",
      "/Reshape_2_output_0\n",
      "/Cast_output_0\n",
      "/Constant_11_output_0\n",
      "/Pad_output_0\n",
      "/sep2_dw/Conv_output_0\n",
      "/sep2_pw/Conv_output_0\n",
      "/Constant_12_output_0\n",
      "/Shape_1_output_0\n",
      "/Gather_1_output_0\n",
      "/Constant_13_output_0\n",
      "/Equal_1_output_0\n",
      "/If_1_output_0\n",
      "/relu_2/Relu_output_0\n",
      "/Transpose_1_output_0\n",
      "/Shape_2_output_0\n",
      "/Constant_14_output_0\n",
      "/Gather_2_output_0\n",
      "/Shape_3_output_0\n",
      "/Constant_15_output_0\n",
      "/Gather_3_output_0\n",
      "/Shape_4_output_0\n",
      "/Constant_16_output_0\n",
      "/Gather_4_output_0\n",
      "/Mul_output_0\n",
      "/Unsqueeze_2_output_0\n",
      "/Constant_17_output_0\n",
      "/Unsqueeze_3_output_0\n",
      "/Concat_1_output_0\n",
      "/Reshape_3_output_0\n",
      "/Unsqueeze_4_output_0\n",
      "/Unsqueeze_5_output_0\n",
      "/Unsqueeze_6_output_0\n",
      "/Unsqueeze_7_output_0\n",
      "/lstm1/LSTM_output_0\n",
      "/lstm1/Squeeze_output_0\n",
      "/lstm2/LSTM_output_0\n",
      "/lstm2/Squeeze_output_0\n",
      "/Concat_2_output_0\n",
      "/fc1/MatMul_output_0\n",
      "/fc1/Add_output_0\n",
      "/relu_3/Relu_output_0\n",
      "/fc2/MatMul_output_0\n",
      "/fc2/Add_output_0\n"
     ]
    }
   ],
   "source": [
    "model_name = \"debug_torch_model.onnx\"\n",
    "model = onnx.load(model_name)\n",
    "with open(\"pickle_input.pkl\", \"rb\") as f:\n",
    "    input_t = pickle.load(f)\n",
    "\n",
    "session = rt.InferenceSession(model_name, providers=['CPUExecutionProvider'])\n",
    "output_names = [ o.name for o in session.get_outputs()]\n",
    "raw_outputs = session.run(None, input_t)\n",
    "outputs_dict = dict(zip(output_names, raw_outputs))\n",
    "l = list(outputs_dict.keys())\n",
    "for i in l:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_1\n",
      "output_2\n",
      "output_3\n",
      "output_6\n",
      "output_7\n",
      "Unsqueeze__97:0\n",
      "Unsqueeze__95:0\n",
      "Unsqueeze__68:0\n",
      "Unsqueeze__66:0\n",
      "StatefulPartitionedCall/vad_model/ExpandDims:0\n",
      "StatefulPartitionedCall/vad_model/separable_conv2d/separable_conv2d/depthwise__111:0\n",
      "StatefulPartitionedCall/vad_model/separable_conv2d/separable_conv2d/depthwise:0\n",
      "StatefulPartitionedCall/vad_model/separable_conv2d/BiasAdd:0\n",
      "StatefulPartitionedCall/vad_model/separable_conv2d/Relu:0\n",
      "StatefulPartitionedCall/vad_model/separable_conv1d/separable_conv2d/depthwise__127:0\n",
      "StatefulPartitionedCall/vad_model/separable_conv1d/separable_conv2d/depthwise:0\n",
      "StatefulPartitionedCall/vad_model/separable_conv1d/BiasAdd:0\n",
      "StatefulPartitionedCall/vad_model/separable_conv1d/Squeeze:0\n",
      "StatefulPartitionedCall/vad_model/separable_conv1d/Relu:0\n",
      "StatefulPartitionedCall/vad_model/separable_conv1d_1/ExpandDims:0\n",
      "StatefulPartitionedCall/vad_model/separable_conv1d_1/separable_conv2d/depthwise:0\n",
      "StatefulPartitionedCall/vad_model/separable_conv1d_1/BiasAdd:0\n",
      "StatefulPartitionedCall/vad_model/separable_conv1d_1/Squeeze:0\n",
      "StatefulPartitionedCall/vad_model/separable_conv1d_1/Relu:0\n",
      "StatefulPartitionedCall/vad_model/separable_conv1d_1/BiasAdd__147:0\n",
      "StatefulPartitionedCall/vad_model/lstm/PartitionedCall/transpose:0\n",
      "LSTM__73:0\n",
      "LSTM__73:1\n",
      "LSTM__73:2\n",
      "Squeeze__75:0\n",
      "StatefulPartitionedCall/vad_model/lstm/PartitionedCall/transpose_1:0\n",
      "StatefulPartitionedCall/vad_model/lstm_2/PartitionedCall/transpose:0\n",
      "LSTM__102:0\n",
      "LSTM__102:1\n",
      "LSTM__102:2\n",
      "Squeeze__104:0\n",
      "StatefulPartitionedCall/vad_model/lstm_2/PartitionedCall/transpose_1:0\n",
      "StatefulPartitionedCall/vad_model/concat_1:0\n",
      "StatefulPartitionedCall/vad_model/dense_3/Tensordot/Shape:0\n",
      "StatefulPartitionedCall/vad_model/dense_3/Tensordot/Shape__162:0\n",
      "StatefulPartitionedCall/vad_model/dense_3/Tensordot/GatherV2:0\n",
      "StatefulPartitionedCall/vad_model/dense_3/Tensordot/concat_1:0\n",
      "StatefulPartitionedCall/vad_model/dense_3/Tensordot__167:0\n",
      "StatefulPartitionedCall/vad_model/dense_3/Tensordot/Reshape:0\n",
      "StatefulPartitionedCall/vad_model/dense_3/Tensordot/MatMul:0\n",
      "StatefulPartitionedCall/vad_model/dense_3/Tensordot:0\n",
      "StatefulPartitionedCall/vad_model/dense_3/BiasAdd:0\n",
      "StatefulPartitionedCall/vad_model/dense_3/Relu:0\n",
      "StatefulPartitionedCall/vad_model/dense_5/Tensordot/Shape:0\n",
      "StatefulPartitionedCall/vad_model/dense_5/Tensordot/Shape__168:0\n",
      "StatefulPartitionedCall/vad_model/dense_5/Tensordot/GatherV2:0\n",
      "StatefulPartitionedCall/vad_model/dense_5/Tensordot/concat_1:0\n",
      "StatefulPartitionedCall/vad_model/dense_5/Tensordot__173:0\n",
      "StatefulPartitionedCall/vad_model/dense_5/Tensordot/Reshape:0\n",
      "StatefulPartitionedCall/vad_model/dense_5/Tensordot/MatMul:0\n",
      "StatefulPartitionedCall/vad_model/dense_5/Tensordot:0\n",
      "StatefulPartitionedCall/vad_model/concat_2:0\n"
     ]
    }
   ],
   "source": [
    "model_name = \"debug_onnx_model.onnx\"\n",
    "orig_model = onnx.load(model_name)\n",
    "with open(\"pickle_input.pkl\", \"rb\") as f:\n",
    "    input_t = pickle.load(f)\n",
    "\n",
    "session2 = rt.InferenceSession(model_name, providers=['CPUExecutionProvider'])\n",
    "output_names2 = [ o.name for o in session2.get_outputs()]\n",
    "raw_outputs2 = session2.run(None, input_t)\n",
    "outputs_dict2 = dict(zip(output_names2, raw_outputs2))\n",
    "l = list(outputs_dict2.keys())\n",
    "for i in l:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 64]),\n",
       " tensor([[[ 1.1455e-01,  2.2319e-03,  3.4622e-05,  1.5677e-02,  5.0729e-02,\n",
       "            2.6100e-03, -2.5539e-01, -1.1169e-02,  2.3027e-02,  2.3777e-01,\n",
       "            4.1674e-02, -1.0629e-02,  2.0085e-02, -3.4918e-03,  6.1300e-03,\n",
       "            3.7393e-04, -7.2495e-01, -9.4491e-04,  1.0627e-02,  5.1566e-03,\n",
       "           -1.5549e-01,  2.6605e-02,  6.0866e-05,  7.1047e-02, -7.1336e-01,\n",
       "           -1.1758e-02,  5.8289e-02,  4.9545e-03,  8.2858e-03, -3.7118e-01,\n",
       "            6.7800e-01, -1.3712e-01,  2.7457e-03, -2.5531e-01,  2.0380e-01,\n",
       "            1.0210e-03, -1.6683e-02,  1.6065e-02,  1.0140e-01, -7.1636e-01,\n",
       "            4.0471e-03, -6.9450e-01, -9.5008e-03, -1.7269e-06,  6.2494e-01,\n",
       "            6.4456e-02,  3.3084e-01,  7.3581e-02, -1.4559e-03, -2.4578e-01,\n",
       "            6.3197e-02,  2.4946e-01,  4.2983e-02, -1.3051e-04, -1.9492e-01,\n",
       "            9.6574e-05,  5.6413e-01,  2.3526e-04, -7.3422e-01, -3.4906e-01,\n",
       "            3.7469e-02,  4.1834e-04,  1.2700e-03,  3.4934e-01]]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {k:torch.from_numpy(v).to(\"cuda\").float() for k,v in input_t.items()}\n",
    "with torch.inference_mode():\n",
    "    outputs = torch_model(**inputs)\n",
    "\n",
    "outputs.shape, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[-4.0561956e-01, -2.6092851e-03, -5.2212199e-05, -9.5241461e-03,\n",
       "         -5.4733064e-03, -1.6409131e-02,  7.6739639e-03, -3.6653925e-03,\n",
       "         -7.4510523e-03,  1.3249981e-01,  8.3374590e-02,  1.0331009e-03,\n",
       "          3.5107995e-03, -3.5438277e-02,  6.4066141e-03,  2.9350645e-04,\n",
       "          7.1306485e-01, -1.4669594e-03, -3.2577369e-02, -1.0248714e-02,\n",
       "         -7.0155728e-01,  9.9166734e-03, -1.1119212e-03, -7.2317589e-03,\n",
       "          7.5774437e-01, -2.4382159e-02,  7.2176002e-02, -4.7024649e-02,\n",
       "         -7.5228459e-01,  7.8379503e-03,  7.2490573e-02, -7.1959072e-01,\n",
       "         -1.2122970e-03, -4.6606508e-01, -7.9160623e-02,  7.1216526e-04,\n",
       "          1.4785431e-02, -7.5878674e-04, -8.8518359e-02,  5.7699770e-01,\n",
       "         -6.3017459e-04,  5.8952105e-01, -6.8233955e-01, -2.9505866e-02,\n",
       "          7.1074140e-01, -7.9221632e-03, -8.5678108e-02, -1.9748281e-01,\n",
       "         -3.2891501e-02, -6.7008495e-02,  1.9274218e-03, -5.1458341e-01,\n",
       "         -6.2436926e-01, -6.7237146e-05, -5.8339804e-01, -6.0665247e-04,\n",
       "          4.5077860e-01, -2.6232151e-03,  7.5409305e-01, -2.7389564e-02,\n",
       "         -2.4093439e-01, -1.5993473e-04,  5.9495639e-04,  5.3479749e-01]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# onnx_output= outputs_dict2['StatefulPartitionedCall/vad_model/lstm/PartitionedCall/transpose:0']\n",
    "# torch_output = outputs_dict['/Reshape_3_output_0']\n",
    "\n",
    "onnx_output= outputs_dict2['LSTM__73:0']\n",
    "# torch_output = outputs_dict['/Unsqueeze_4_output_0']\n",
    "\n",
    "display(onnx_output.shape)#, display(torch_output.shape)\n",
    "#fix onnx output \n",
    "onnx_output_fixed = onnx_output.squeeze(1)  # Remove num_directions dimension\n",
    "onnx_output_fixed = onnx_output_fixed.transpose(1, 0, 2)\n",
    "onnx_output_fixed\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-4.0561956e-01, -2.6092851e-03, -5.2212199e-05,\n",
       "          -9.5241461e-03, -5.4733064e-03, -1.6409131e-02,\n",
       "           7.6739639e-03, -3.6653925e-03, -7.4510523e-03,\n",
       "           1.3249981e-01,  8.3374590e-02,  1.0331009e-03,\n",
       "           3.5107995e-03, -3.5438277e-02,  6.4066141e-03,\n",
       "           2.9350645e-04,  7.1306485e-01, -1.4669594e-03,\n",
       "          -3.2577369e-02, -1.0248714e-02, -7.0155728e-01,\n",
       "           9.9166734e-03, -1.1119212e-03, -7.2317589e-03,\n",
       "           7.5774437e-01, -2.4382159e-02,  7.2176002e-02,\n",
       "          -4.7024649e-02, -7.5228459e-01,  7.8379503e-03,\n",
       "           7.2490573e-02, -7.1959072e-01, -1.2122970e-03,\n",
       "          -4.6606508e-01, -7.9160623e-02,  7.1216526e-04,\n",
       "           1.4785431e-02, -7.5878674e-04, -8.8518359e-02,\n",
       "           5.7699770e-01, -6.3017459e-04,  5.8952105e-01,\n",
       "          -6.8233955e-01, -2.9505866e-02,  7.1074140e-01,\n",
       "          -7.9221632e-03, -8.5678108e-02, -1.9748281e-01,\n",
       "          -3.2891501e-02, -6.7008495e-02,  1.9274218e-03,\n",
       "          -5.1458341e-01, -6.2436926e-01, -6.7237146e-05,\n",
       "          -5.8339804e-01, -6.0665247e-04,  4.5077860e-01,\n",
       "          -2.6232151e-03,  7.5409305e-01, -2.7389564e-02,\n",
       "          -2.4093439e-01, -1.5993473e-04,  5.9495639e-04,\n",
       "           5.3479749e-01]]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /Unsqueeze\n",
      "1 /Constant\n",
      "2 /Reshape\n",
      "3 /conv_dw/Conv\n",
      "4 /conv_pw/Conv\n",
      "5 /relu/Relu\n",
      "6 /pool/MaxPool\n",
      "7 /sep1_dw/Conv\n",
      "8 /sep1_pw/Conv\n",
      "9 /Constant_1\n",
      "10 /Shape\n",
      "11 /Gather\n",
      "12 /Constant_2\n",
      "13 /Equal\n",
      "14 /If\n",
      "15 /relu_1/Relu\n",
      "16 /Unsqueeze_1\n",
      "17 /Constant_3\n",
      "18 /Constant_4\n",
      "19 /ConstantOfShape\n",
      "20 /Concat\n",
      "21 /Constant_5\n",
      "22 /Reshape_1\n",
      "23 /Constant_6\n",
      "24 /Constant_7\n",
      "25 /Constant_8\n",
      "26 /Constant_9\n",
      "27 /Slice\n",
      "28 /Transpose\n",
      "29 /Constant_10\n",
      "30 /Reshape_2\n",
      "31 /Cast\n",
      "32 /Constant_11\n",
      "33 /Pad\n",
      "34 /sep2_dw/Conv\n",
      "35 /sep2_pw/Conv\n",
      "36 /Constant_12\n",
      "37 /Shape_1\n",
      "38 /Gather_1\n",
      "39 /Constant_13\n",
      "40 /Equal_1\n",
      "41 /If_1\n",
      "42 /relu_2/Relu\n",
      "43 /Transpose_1\n",
      "44 /Shape_2\n",
      "45 /Constant_14\n",
      "46 /Gather_2\n",
      "47 /Shape_3\n",
      "48 /Constant_15\n",
      "49 /Gather_3\n",
      "50 /Shape_4\n",
      "51 /Constant_16\n",
      "52 /Gather_4\n",
      "53 /Mul\n",
      "54 /Unsqueeze_2\n",
      "55 /Constant_17\n",
      "56 /Unsqueeze_3\n",
      "57 /Concat_1\n",
      "58 /Reshape_3\n",
      "59 /Unsqueeze_4\n",
      "60 /Unsqueeze_5\n",
      "61 /Unsqueeze_6\n",
      "62 /Unsqueeze_7\n",
      "63 /lstm1/LSTM\n",
      "64 /lstm1/Squeeze\n",
      "65 /lstm2/LSTM\n",
      "66 /lstm2/Squeeze\n",
      "67 /Concat_2\n",
      "68 /fc1/MatMul\n",
      "69 /fc1/Add\n",
      "70 /relu_3/Relu\n",
      "71 /fc2/MatMul\n",
      "72 /fc2/Add\n",
      "73 /sig/Sigmoid\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(model.graph.node):\n",
    "    print(i, node.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm_node = model.graph.node[63]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv_dw.weight\n",
      "1 conv_pw.weight\n",
      "2 conv_pw.bias\n",
      "3 sep1_dw.weight\n",
      "4 sep1_pw.weight\n",
      "5 sep1_pw.bias\n",
      "6 sep2_dw.weight\n",
      "7 sep2_pw.weight\n",
      "8 sep2_pw.bias\n",
      "9 fc1.bias\n",
      "10 fc2.bias\n",
      "11 onnx::LSTM_255\n",
      "12 onnx::LSTM_256\n",
      "13 onnx::LSTM_257\n",
      "14 onnx::LSTM_275\n",
      "15 onnx::LSTM_276\n",
      "16 onnx::LSTM_277\n",
      "17 onnx::MatMul_278\n",
      "18 onnx::MatMul_279\n"
     ]
    }
   ],
   "source": [
    "for i, initializer in enumerate(model.graph.initializer):\n",
    "    print(i, initializer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_lstm_node = orig_model.graph.node[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 new_shape__175\n",
      "1 const_fold_opt__178\n",
      "2 StatefulPartitionedCall/vad_model/separable_conv2d/separable_conv2d/ReadVariableOp_1:0\n",
      "3 StatefulPartitionedCall/vad_model/separable_conv2d/BiasAdd/ReadVariableOp:0\n",
      "4 const_fold_opt__179\n",
      "5 StatefulPartitionedCall/vad_model/separable_conv1d/ExpandDims_2:0\n",
      "6 StatefulPartitionedCall/vad_model/separable_conv1d/BiasAdd/ReadVariableOp:0\n",
      "7 const_fold_opt__180\n",
      "8 StatefulPartitionedCall/vad_model/separable_conv1d_1/ExpandDims_2:0\n",
      "9 StatefulPartitionedCall/vad_model/separable_conv1d_1/BiasAdd/ReadVariableOp:0\n",
      "10 new_shape__177\n",
      "11 W0__70\n",
      "12 R0__71\n",
      "13 B0__72\n",
      "14 new_shape__176\n",
      "15 W0__99\n",
      "16 R0__100\n",
      "17 B0__101\n",
      "18 StatefulPartitionedCall/vad_model/dense_3/Tensordot/free:0\n",
      "19 StatefulPartitionedCall/vad_model/dense/Tensordot/Const_2:0\n",
      "20 StatefulPartitionedCall/vad_model/dense/Tensordot/Reshape_shape__186\n",
      "21 StatefulPartitionedCall/vad_model/dense_3/Tensordot/ReadVariableOp:0\n",
      "22 StatefulPartitionedCall/vad_model/dense_3/BiasAdd/ReadVariableOp:0\n",
      "23 StatefulPartitionedCall/vad_model/dense_5/Tensordot/Const_2:0\n",
      "24 StatefulPartitionedCall/vad_model/dense_5/Tensordot/Reshape_shape__183\n",
      "25 StatefulPartitionedCall/vad_model/dense_5/Tensordot/ReadVariableOp:0\n",
      "26 StatefulPartitionedCall/vad_model/dense_5/BiasAdd/ReadVariableOp:0\n"
     ]
    }
   ],
   "source": [
    "for i, initializer in enumerate(orig_model.graph.initializer):\n",
    "    print(i, initializer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = model.graph.initializer[11]\n",
    "R = model.graph.initializer[12]\n",
    "B = model.graph.initializer[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_ori = orig_model.graph.initializer[11]\n",
    "R_ori = orig_model.graph.initializer[12]\n",
    "B_ori = orig_model.graph.initializer[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_torch = state_dict['lstm1.weight_ih_l0'].numpy()\n",
    "R_torch = state_dict['lstm1.weight_hh_l0'].numpy()\n",
    "B_torch = state_dict['lstm1.bias_ih_l0'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         ...,\n",
       "         [-0.1447528 , -0.2812652 , -0.9021763 , ...,  0.38451663,\n",
       "           0.08557338, -0.23741567],\n",
       "         [-0.33152345, -0.22362734, -0.00653614, ..., -0.6657253 ,\n",
       "          -0.9935426 , -0.5834838 ],\n",
       "         [-0.1252819 ,  0.27870315,  0.13105348, ...,  0.18257932,\n",
       "           0.83363706,  0.32151163]]], shape=(1, 256, 80), dtype=float32),\n",
       " array([[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         ...,\n",
       "         [ 0.48578432,  0.18361041,  0.17614032, ...,  0.28419352,\n",
       "           0.21935251,  0.23873608],\n",
       "         [ 0.9871485 ,  0.25750008,  0.3457416 , ...,  0.0128186 ,\n",
       "           0.17374223, -1.0447848 ],\n",
       "         [ 0.6165874 ,  0.00960901, -0.15370113, ..., -0.12160549,\n",
       "           0.13375849, -0.1566813 ]]], shape=(1, 256, 64), dtype=float32),\n",
       " array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.01711245,\n",
       "          0.14764981,  0.50355387, -0.22906572,  0.20824099, -0.15586254,\n",
       "          0.00930299, -0.07181587, -0.36348695, -0.21917056, -0.03430693,\n",
       "          0.01936509,  0.0732428 ,  0.02132085, -0.04817469, -0.19448662,\n",
       "          0.02668704, -0.01051636, -0.07731544,  0.18053877, -0.27824074,\n",
       "         -0.18177325,  0.1287223 , -0.25381345,  0.31081778, -0.31881738,\n",
       "          0.00224579, -0.11072196,  0.23704076, -0.18509422,  0.01947942,\n",
       "          0.5615999 ,  0.0341227 , -0.0141672 ,  0.2986884 ,  0.11687654,\n",
       "          0.05840215,  0.02856571, -0.37568069, -0.01344445,  0.4890547 ,\n",
       "          0.10510316, -0.06523227,  0.7556797 ,  0.27649796,  0.05268467,\n",
       "          0.83451676,  0.22893754,  0.05091829,  0.10331462, -0.06169686,\n",
       "          0.51391125, -0.3352141 ,  0.10298961,  0.07356088,  0.3229077 ,\n",
       "          0.21895128,  0.14940336,  0.15451097, -0.10971097,  0.1409103 ,\n",
       "          0.15493096,  0.0653341 ,  0.0350092 ,  1.1853343 ,  1.0495847 ,\n",
       "          1.1778699 ,  1.2088264 ,  1.070219  ,  1.0761228 ,  0.7851461 ,\n",
       "          1.1875204 ,  0.79502434,  1.2478586 ,  0.920171  ,  0.97045696,\n",
       "          0.93618983,  1.015574  ,  1.4090503 ,  1.4277344 ,  0.70115477,\n",
       "          1.0281304 ,  1.0388029 ,  1.0852908 ,  0.722335  ,  1.1929784 ,\n",
       "          1.170158  ,  0.92589605,  0.15882541,  1.0930396 ,  1.0993298 ,\n",
       "          1.0310944 ,  0.74484974,  0.24664085,  1.2120417 ,  0.3447383 ,\n",
       "          0.97996694,  0.65873784,  0.7331637 ,  1.137003  ,  0.79660475,\n",
       "          0.90655404,  1.4763683 ,  0.72963434,  0.8534872 ,  0.4699064 ,\n",
       "          0.73902696,  0.6549959 ,  0.7533111 ,  0.96449065,  0.8094826 ,\n",
       "          0.78444225,  1.0549477 ,  0.9355712 ,  1.3554686 ,  0.5373093 ,\n",
       "          1.4088607 ,  0.9384141 ,  0.57283413,  1.1926059 ,  1.008482  ,\n",
       "          1.0146832 ,  0.21048811,  1.0570966 ,  0.9853817 ,  1.2042825 ,\n",
       "          1.3159114 ,  0.8128847 , -1.2024468 , -1.1972345 , -1.6814238 ,\n",
       "         -0.9797607 , -1.27846   , -0.92026025, -0.7944491 , -1.1157045 ,\n",
       "         -0.4315374 , -1.0286881 , -0.8858641 , -0.98982203, -1.0094327 ,\n",
       "         -1.0368948 , -1.3608756 , -1.2332478 , -0.7278418 , -1.017614  ,\n",
       "         -0.9614874 , -1.2658296 , -0.4440942 , -1.0112051 , -1.2988802 ,\n",
       "         -0.6720826 , -0.4696432 , -0.77422225, -1.1015756 , -0.9203724 ,\n",
       "         -0.9818905 , -0.06154662, -1.2315212 , -0.9063382 , -1.0140896 ,\n",
       "         -0.64457065, -1.0318521 , -1.2538794 , -0.85500693, -0.93511975,\n",
       "         -1.1006876 , -0.7161899 , -1.3425419 , -0.5750095 , -0.6737947 ,\n",
       "         -1.4106756 , -1.029809  , -1.0171753 , -1.6439993 , -1.0133798 ,\n",
       "         -1.105866  , -1.0388858 , -1.2937717 , -1.0512204 , -1.0736467 ,\n",
       "         -1.0414037 , -0.646395  , -1.5155135 , -1.2274332 , -1.1640866 ,\n",
       "         -0.3649991 , -0.9473856 , -1.126292  , -1.3592135 , -1.3812455 ,\n",
       "         -0.8478939 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ]], dtype=float32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_ori.name = 'W'\n",
    "R_ori.name = 'R'\n",
    "B_ori.name = 'B'\n",
    "import numpy as np\n",
    "W_ori_weight = np.frombuffer(W_ori.raw_data, dtype=np.float32).reshape(W_ori.dims)\n",
    "W_weight = np.frombuffer(W.raw_data, dtype=np.float32).reshape(W.dims)\n",
    "\n",
    "R_ori_weight = np.frombuffer(R_ori.raw_data, dtype=np.float32).reshape(R_ori.dims)\n",
    "R_weight = np.frombuffer(R.raw_data, dtype=np.float32).reshape(R.dims)\n",
    "\n",
    "B_ori_weight = np.frombuffer(B_ori.raw_data, dtype=np.float32).reshape(B_ori.dims)\n",
    "B_weight = np.frombuffer(B.raw_data, dtype=np.float32).reshape(B.dims)\n",
    "\n",
    "W_ori_weight - W_weight, R_ori_weight - R_weight, B_ori_weight - B_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.4867446 ,  0.47443914, -0.590404  , ..., -0.03301766,\n",
       "          0.03501979, -0.10179292],\n",
       "        [-0.4780938 , -0.2546657 , -0.42414826, ...,  0.63041824,\n",
       "          0.26865023,  0.75948215],\n",
       "        [-0.8182535 , -0.43482986, -0.21190313, ...,  0.07235646,\n",
       "         -0.25456637, -0.1706717 ],\n",
       "        ...,\n",
       "        [ 0.06247028, -0.01019134, -0.66108805, ...,  0.32636583,\n",
       "          0.27987358,  0.0863558 ],\n",
       "        [ 0.03873489,  0.13783218,  0.075941  , ..., -0.39508176,\n",
       "         -0.3009435 , -0.15503898],\n",
       "        [-0.4833058 , -0.17500852, -0.10183387, ...,  0.33798772,\n",
       "          0.694602  ,  0.58902663]]], shape=(1, 256, 80), dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_ori_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#check lstm \n",
    "W_torch = state_dict['lstm1.weight_ih_l0'].numpy()\n",
    "print(W_torch - W_ori_weight)\n",
    "\n",
    "R_torch = state_dict['lstm1.weight_hh_l0'].numpy()\n",
    "print(R_torch - R_ori_weight)\n",
    "\n",
    "B_torch = state_dict['lstm1.bias_ih_l0'].numpy()\n",
    "print(B_torch - B_ori_weight[:, :256])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], shape=(1, 256, 80), dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_torch_loaded = torch.load('ih_l0.pth')\n",
    "W_torch_loaded.detach().numpy() - W_ori_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [-0.1447528  -0.2812652  -0.9021763  ...  0.38451663  0.08557338\n",
      "   -0.23741567]\n",
      "  [-0.33152345 -0.22362734 -0.00653614 ... -0.6657253  -0.9935426\n",
      "   -0.5834838 ]\n",
      "  [-0.1252819   0.27870315  0.13105348 ...  0.18257932  0.83363706\n",
      "    0.32151163]]]\n",
      "[[[ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.48578432  0.18361041  0.17614032 ...  0.28419352  0.21935251\n",
      "    0.23873608]\n",
      "  [ 0.9871485   0.25750008  0.3457416  ...  0.0128186   0.17374223\n",
      "   -1.0447848 ]\n",
      "  [ 0.6165874   0.00960901 -0.15370113 ... -0.12160549  0.13375849\n",
      "   -0.1566813 ]]]\n"
     ]
    }
   ],
   "source": [
    "#check lstm \n",
    "W_torch = state_dict['lstm1.weight_ih_l0'].numpy()\n",
    "print(W_torch - W_weight)\n",
    "\n",
    "R_torch = state_dict['lstm1.weight_hh_l0'].numpy()\n",
    "print(R_torch - R_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dims: 1\n",
       "dims: 512\n",
       "data_type: 1\n",
       "name: \"onnx::LSTM_257\"\n",
       "raw_data: \"9\\033\\207\\2766|\\n\\276\\025>\\325\\276x\\345\\375\\276\\242-;\\276E\\230\\325\\276Yc$\\275\\r\\245\\204\\276;\\212\\224\\276\\'\\353\\302\\276\\033\\304~\\275\\226\\361H\\276\\331WI\\276\\n*B\\276\\342\\035I\\277b\\264\\030\\277\\017\\261G\\276\\337l\\325\\276t\\347r\\2762\\t\\327\\276P\\034\\324=\\204S\\022\\277\\2475\\372\\275#b\\346\\276\\315\\311\\336>U\\016\\214\\276\\326\\304\\372\\276\\235[\\252\\276\\312\\235\\221>%bD\\275\\227\\236\\302\\276v\\334a=\\334E8\\276\\246\\215\\375=\\020~\\240=\\253\\257\\337\\276\\000\\332\\341=F\\313\\210=:\\214\\271\\276\\327\\233\\\\\\276\\265a\\240\\276\\230\\375\\251=\\236\\205\\205>\\231\\016\\016?\\274j\\315;\\\"U\\\\\\276~\\321\\236>H\\234.\\276[z\\021\\277W\\352,\\276\\211k\\021\\2777\\217\\271=N\\036\\233\\276M\\354\\254\\275sw\\317<\\211\\2713\\277\\t;\\037\\277Y\\212,\\277\\363\\036Y>\\263\\020\\231\\276)\\031+\\277\\332\\3306\\276\\263\\251\\033\\277J\\177\\302\\275\\000y\\222\\275E\\361\\000<\\221\\231\\354\\275\\357H\\232<\\307q\\245\\275\\316\\033\\003=?\\264\\013\\276,DK=\\316\\267\\264>\\232\\244(\\274\\236\\032G=\\246w\\272\\275\\306\\t\\001\\275B\\316%\\276\\273 \\212=\\316\\265\\340=\\350\\307\\343=>\\t\\267=\\360n\\250;&\\201\\032\\276\\251\\n\\211>\\r\\366;>\\357\\251f\\275\\214\\252\\214>\\314\\214\\212\\275jU\\265=\\014,\\247\\275\\204YI<\\245q\\033\\276\\2029\\264>\\245\\032\\002\\276\\233\\243v\\276\\253\\242\\013\\276\\307\\361B=\\\\\\202\\366\\275\\340\\\"\\366=\\210\\024\\301\\275\\230\\206\\265\\274\\250\\211\\330<\\252\\321-\\275\\033s\\245\\276\\317\\267\\317\\274\\202\\204\\231=\\243\\035\\276\\276\\035z\\217\\276\\006\\264P=\\324#\\361\\276(\\337v\\275i\\246\\271<\\201Q\\034\\275\\0215\\n\\276\\016\\203\\245\\276K{\\232;\\204s\\330\\275H&\\026>\\242\\272\\275\\275\\214\\264s\\276\\2323\\273=\\300}\\005\\275\\223\\202\\263\\274\\275\\003I\\276\\344\\211\\212\\275g\\260\\014=f\\242\\313<L\\332^\\275\\227@\\037>l\\253\\306>\\026GW\\276=\\204\\002>\\365\\246\\375\\275\\206-\\002\\276t\\310\\265\\274\\372d,\\274\\211\\370j\\276\\311Tj<\\304\\316\\222\\275\\335\\366*= \\371\\017\\276C\\335\\235<2\\231\\255\\275\\3157\\r>\\244\\177\\241=\\240\\320\\223\\275\\014\\360\\362<!]-\\274{\\244\\351:\\226J\\224=hk\\253<\\237\\000y>Z\\315k\\276\\233\\222\\242\\275\\001\\227\\311\\275V\\222\\256=\\255\\351*>wP\\334\\27588\\244>7c\\321\\275e\\352\\010=3\\2326>\\354\\277r>\\370\\361\\022\\2754\\360\\321;\\235\\320\\262\\2760\\343d\\275\\214\\344)>`R\\243=\\027`\\037<\\321\\312\\304>\\254|t\\273\\364?\\324=\\364!\\272>\\320\\266,>s\\261\\226=\\335m\\205=\\207bI\\276\\2428C>B7\\251\\276\\241\\3510\\273\\323ya>\\377\\312k>D\\376\\233\\274\\377\\226v>_\\261\\371=e\\310\\006\\276\\316\\343b\\275\\216\\302\\262=\\025&\\314=\\0017u=7\\302\\220?\\336@\\232?Lo\\310?\\340\\243\\177?xM\\231?\\352\\307s?\\364s(?\\211)\\225?#\\325H?\\304Z\\202?\\2479o?\\005\\026f?\\221Yz?_\\376_?8\\323\\266?m\\346\\253?\\324\\314V?\\301\\261\\215?\\350tw?\\217\\266\\216?}56?\\355\\355\\230?f\\014\\237?\\341br?\\340\\321\\315>\\033\\336\\\\?\\255\\215\\202?\\355\\302n?\\304\\200T?\\214\\274\\323>(_\\215?\\341\\\\*?\\266\\262`?\\26111?+Wi?M\\341\\257?+\\277B?\\315\\267i?|E\\220?\\036{,?\\243{\\202?\\025\\266\\014?_\\256??\\234\\t\\205?\\202\\344??m\\270\\210?\\235%\\226?\\351\\376s?\\236s\\220?\\252\\027\\200?\\256S\\224?B[:?\\274\\007\\212?\\376\\212o?\\267\\003K?\\257 \\266?\\356K}?\\004\\264\\240?q1\\252>\\310\\353l?\\275\\023n?\\027R\\245?*2\\265?\\246l_?\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.graph.initializer[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating ONNX LSTM Model: lstm_forward_default_activations.onnx ---\n",
      "Input Size: 10, Hidden Size: 64\n",
      "Batch Size: 1, Sequence Length: 5\n",
      "Direction: forward, Activations: ['Sigmoid', 'Tanh', 'Tanh'], Bias: True\n",
      "ONNX LSTM model saved to lstm_forward_default_activations.onnx\n",
      "\n",
      "--- Verifying ONNX Model: lstm_forward_default_activations.onnx ---\n",
      "ONNX Runtime session created successfully.\n",
      "Model Inputs: ['X', 'initial_h', 'initial_c']\n",
      "Model Outputs: ['Y', 'Y_h', 'Y_c']\n",
      "Error verifying ONNX model: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: initial_h for the following indices\n",
      " index: 1 Got: 2 Expected: 1\n",
      " Please fix either the inputs/outputs or the model.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx import helper\n",
    "from onnx import TensorProto\n",
    "import numpy as np\n",
    "import onnxruntime as rt\n",
    "\n",
    "def create_single_lstm_onnx_model(\n",
    "    model_name: str = \"single_lstm_model.onnx\",\n",
    "    input_size: int = 10,\n",
    "    hidden_size: int = 64,\n",
    "    batch_size: int = 1,\n",
    "    sequence_length: int = 5,\n",
    "    direction: str = \"forward\", # \"forward\", \"reverse\", or \"bidirectional\"\n",
    "    activations: list = None, # e.g., [\"Sigmoid\", \"Tanh\", \"Tanh\"]\n",
    "    bias: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Manually creates an ONNX model with a single LSTM layer.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the ONNX file to save.\n",
    "        input_size (int): The number of expected features in the input `X`.\n",
    "        hidden_size (int): The number of features in the hidden state `H`.\n",
    "        batch_size (int): The batch size for the input.\n",
    "        sequence_length (int): The length of the input sequence.\n",
    "        direction (str): The direction of the LSTM. Can be \"forward\", \"reverse\", or \"bidirectional\".\n",
    "        activations (list, optional): List of strings for activation functions.\n",
    "                                      Order: [f, g, h] (forget, cell, output).\n",
    "                                      Defaults to [\"Sigmoid\", \"Tanh\", \"Tanh\"] if None.\n",
    "        bias (bool): Whether the LSTM layer includes bias terms.\n",
    "    \"\"\"\n",
    "    print(f\"--- Creating ONNX LSTM Model: {model_name} ---\")\n",
    "    print(f\"Input Size: {input_size}, Hidden Size: {hidden_size}\")\n",
    "    print(f\"Batch Size: {batch_size}, Sequence Length: {sequence_length}\")\n",
    "    print(f\"Direction: {direction}, Activations: {activations}, Bias: {bias}\")\n",
    "\n",
    "    # Determine number of directions for weight/bias shapes\n",
    "    num_directions = 0\n",
    "    if direction == \"forward\" or direction == \"reverse\":\n",
    "        num_directions = 1\n",
    "    elif direction == \"bidirectional\":\n",
    "        num_directions = 2\n",
    "    else:\n",
    "        raise ValueError(\"Direction must be 'forward', 'reverse', or 'bidirectional'\")\n",
    "\n",
    "    # Default activations if not provided\n",
    "    if activations is None:\n",
    "        activations = [\"Sigmoid\", \"Tanh\", \"Tanh\"] # f, g, h\n",
    "\n",
    "    # 1. Define Model Inputs\n",
    "    # X: input sequence (seq_len, batch_size, input_size)\n",
    "    X = helper.make_tensor_value_info('X', TensorProto.FLOAT, [sequence_length, batch_size, input_size])\n",
    "    # initial_h: initial hidden state (num_directions, batch_size, hidden_size)\n",
    "    initial_h = helper.make_tensor_value_info('initial_h', TensorProto.FLOAT, [num_directions, batch_size, hidden_size])\n",
    "    # initial_c: initial cell state (num_directions, batch_size, hidden_size)\n",
    "    initial_c = helper.make_tensor_value_info('initial_c', TensorProto.FLOAT, [num_directions, batch_size, hidden_size])\n",
    "\n",
    "    # 2. Define Initializers (Weights and Biases)\n",
    "    # W: Weight tensor (num_directions, 4*hidden_size, input_size)\n",
    "    # (W_ii|W_if|W_ic|W_io) for each direction\n",
    "    W_shape = [num_directions, 4 * hidden_size, input_size]\n",
    "    W = helper.make_tensor('W', TensorProto.FLOAT, W_shape,\n",
    "                           np.random.rand(*W_shape).astype(np.float32).flatten())\n",
    "\n",
    "    # R: Recurrence weight tensor (num_directions, 4*hidden_size, hidden_size)\n",
    "    # (R_hi|R_hf|R_hc|R_ho) for each direction\n",
    "    R_shape = [num_directions, 4 * hidden_size, hidden_size]\n",
    "    R = helper.make_tensor('R', TensorProto.FLOAT, R_shape,\n",
    "                           np.random.rand(*R_shape).astype(np.float32).flatten())\n",
    "\n",
    "    # B: Bias tensor (num_directions, 8*hidden_size)\n",
    "    # (W_ib|W_fb|W_cb|W_ob|R_ib|R_fb|R_cb|R_ob) for each direction\n",
    "    # If bias=False, this initializer should not be present.\n",
    "    # initializers = [W_ori, R_ori]\n",
    "    initializers = [W, R]\n",
    "    lstm_node_inputs = ['X', 'W', 'R'] # Required inputs for LSTM node\n",
    "\n",
    "    if bias:\n",
    "        # B_shape = [num_directions, 8 * hidden_size]\n",
    "        # B = helper.make_tensor('B', TensorProto.FLOAT, B_shape,\n",
    "        #                        np.random.rand(*B_shape).astype(np.float32).flatten())\n",
    "        initializers.append(B_ori)\n",
    "        # initializers.append(B)\n",
    "        lstm_node_inputs.append('B')\n",
    "    else:\n",
    "        # If no bias, B input is optional and should be an empty string\n",
    "        lstm_node_inputs.append('') # Placeholder for optional B input\n",
    "\n",
    "    # Add initial_h and initial_c to node inputs\n",
    "    lstm_node_inputs.extend(['', 'initial_h', 'initial_c']) # sequence_lens is empty string\n",
    "\n",
    "    # 3. Define Model Outputs\n",
    "    # Y: Output sequence (seq_len, num_directions, batch_size, hidden_size)\n",
    "    # Note: The ONNX LSTM output Y has num_directions as its second dimension.\n",
    "    Y = helper.make_tensor_value_info('Y', TensorProto.FLOAT, [sequence_length, num_directions, batch_size, hidden_size])\n",
    "    # Y_h: Final hidden state (num_directions, batch_size, hidden_size)\n",
    "    Y_h = helper.make_tensor_value_info('Y_h', TensorProto.FLOAT, [num_directions, batch_size, hidden_size])\n",
    "    # Y_c: Final cell state (num_directions, batch_size, hidden_size)\n",
    "    Y_c = helper.make_tensor_value_info('Y_c', TensorProto.FLOAT, [num_directions, batch_size, hidden_size])\n",
    "\n",
    "    # 4. Create the LSTM Node\n",
    "    lstm_node_attributes = {\n",
    "        \"hidden_size\": hidden_size,\n",
    "        \"direction\": direction,\n",
    "        \"activations\": activations\n",
    "    }\n",
    "\n",
    "    lstm_node = helper.make_node(\n",
    "        'LSTM',\n",
    "        inputs=lstm_node_inputs,\n",
    "        outputs=['Y', 'Y_h', 'Y_c'],\n",
    "        name='my_lstm_node',\n",
    "        **lstm_node_attributes\n",
    "    )\n",
    "\n",
    "    # 5. Create the Graph\n",
    "    graph_def = helper.make_graph(\n",
    "        [lstm_node],\n",
    "        'lstm_graph',\n",
    "        [X, initial_h, initial_c], # Graph inputs\n",
    "        [Y, Y_h, Y_c],             # Graph outputs\n",
    "        initializer=initializers  # Initializers (weights, biases)\n",
    "    )\n",
    "\n",
    "    # 6. Create the Model\n",
    "    # Set opset version (e.g., 14 for LSTM)\n",
    "    opset_imports = [helper.make_opsetid(\"ai.onnx\", 10)] # LSTM is in ai.onnx domain\n",
    "    model_def = helper.make_model(graph_def, producer_name='manual-onnx-lstm', opset_imports=opset_imports, ir_version=10)\n",
    "\n",
    "    # 7. Save the Model\n",
    "    onnx.save(model_def, model_name)\n",
    "    print(f\"ONNX LSTM model saved to {model_name}\")\n",
    "\n",
    "    return model_name\n",
    "\n",
    "def verify_onnx_model(model_path: str, input_size: int, hidden_size: int,\n",
    "                       batch_size: int, sequence_length: int, num_directions: int):\n",
    "    \"\"\"\n",
    "    Loads the created ONNX model and runs a dummy inference to verify its structure.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Verifying ONNX Model: {model_path} ---\")\n",
    "    try:\n",
    "        session = rt.InferenceSession(model_path, providers=['CPUExecutionProvider'])\n",
    "        print(\"ONNX Runtime session created successfully.\")\n",
    "\n",
    "        # Prepare dummy input data\n",
    "        dummy_X = np.random.rand(sequence_length, batch_size, input_size).astype(np.float32)\n",
    "        dummy_initial_h = np.zeros((num_directions, batch_size, hidden_size), dtype=np.float32)\n",
    "        dummy_initial_c = np.zeros((num_directions, batch_size, hidden_size), dtype=np.float32)\n",
    "\n",
    "        input_names = [input.name for input in session.get_inputs()]\n",
    "        output_names = [output.name for output in session.get_outputs()]\n",
    "\n",
    "        print(f\"Model Inputs: {input_names}\")\n",
    "        print(f\"Model Outputs: {output_names}\")\n",
    "\n",
    "        # Create input feed dictionary\n",
    "        input_feed = {\n",
    "            'X': dummy_X,\n",
    "            'initial_h': dummy_initial_h,\n",
    "            'initial_c': dummy_initial_c\n",
    "        }\n",
    "\n",
    "        # Run inference\n",
    "        outputs = session.run(output_names, input_feed)\n",
    "\n",
    "        print(\"Inference successful.\")\n",
    "        print(f\"Output Y shape: {outputs[0].shape} (expected: ({sequence_length}, {num_directions}, {batch_size}, {hidden_size}))\")\n",
    "        print(f\"Output Y_h shape: {outputs[1].shape} (expected: ({num_directions}, {batch_size}, {hidden_size}))\")\n",
    "        print(f\"Output Y_c shape: {outputs[2].shape} (expected: ({num_directions}, {batch_size}, {hidden_size}))\")\n",
    "\n",
    "        # Basic shape validation\n",
    "        assert outputs[0].shape == (sequence_length, num_directions, batch_size, hidden_size)\n",
    "        assert outputs[1].shape == (num_directions, batch_size, hidden_size)\n",
    "        assert outputs[2].shape == (num_directions, batch_size, hidden_size)\n",
    "        print(\"Output shapes match expectations.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error verifying ONNX model: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: Unidirectional LSTM (forward) with default activations\n",
    "    model_path_forward = create_single_lstm_onnx_model(\n",
    "        model_name=\"lstm_forward_default_activations.onnx\",\n",
    "        input_size=10,\n",
    "        hidden_size=64,\n",
    "        batch_size=1,\n",
    "        sequence_length=5,\n",
    "        direction=\"forward\",\n",
    "        activations=[\"Sigmoid\", \"Tanh\", \"Tanh\"] # Explicitly specify common defaults\n",
    "    )\n",
    "    verify_onnx_model(model_path_forward, 10, 64, 2, 5, 1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
